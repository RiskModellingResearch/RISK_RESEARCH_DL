{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nmt_with_attention_rus_class_version.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_qNSzzyaCbD"
      },
      "source": [
        "##### Слямзино с  Copyright 2019 The TensorFlow Authors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "# Neural machine translation with attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOpGoE2T-YXS"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/nmt_with_attention.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwtNgENbx2g"
      },
      "source": [
        "Будем создавать свой автопереводчик. На основе документации tf попробуем осознать, как работает внимание.\n",
        "Пример ниже про испанский, попробуем получить тоже самое для русского\n",
        "\n",
        "<img src=\"https://tensorflow.org/images/spanish-english.png\" alt=\"spanish-english attention plot\">\n",
        "\n",
        "Note: This example takes approximately 10 minutes to run on a single P100 GPU. (больше :)))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:05:46.319060Z",
          "iopub.status.busy": "2021-04-02T02:05:46.318253Z",
          "iopub.status.idle": "2021-04-02T02:05:53.942328Z",
          "shell.execute_reply": "2021-04-02T02:05:53.941694Z"
        },
        "id": "tnxXKDjq3jEL"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfodePkj3jEa"
      },
      "source": [
        "## Download and prepare the dataset\n",
        "\n",
        "Возьмем готовый дата сет http://www.manythings.org/anki/. Данные устроены следующим образом:\n",
        "\n",
        "```\n",
        "May I borrow this book?\tМогу ли я одолжить книгу\n",
        "```\n",
        "Плюс какая-то дичь... (для русского языка в частности)\n",
        "\n",
        "Что нам надо еще сделать с текстом\n",
        "1. добавить *start* и *end* токен в каждое предложении.\n",
        "2. Почистим все от ненужного (разные непонятные знаки).\n",
        "3. Создать пару словарей (dictionaries mapping from word → id and id → word).\n",
        "4. Ну и уровнять предложение по длине."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:05:53.949099Z",
          "iopub.status.busy": "2021-04-02T02:05:53.948369Z",
          "iopub.status.idle": "2021-04-02T02:05:54.223340Z",
          "shell.execute_reply": "2021-04-02T02:05:54.223810Z"
        },
        "id": "kRVATYOgJs1b"
      },
      "source": [
        "# Путь до файла\n",
        "\n",
        "path_to_file = \"rus.txt\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC3ZkLq5Alc9",
        "outputId": "d325fa7d-11da-44e1-fe3d-91e1c18e08f0"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct  2 13:02:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    78W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:05:54.230405Z",
          "iopub.status.busy": "2021-04-02T02:05:54.229722Z",
          "iopub.status.idle": "2021-04-02T02:05:54.232166Z",
          "shell.execute_reply": "2021-04-02T02:05:54.231684Z"
        },
        "id": "rd0jw-eC3jEh"
      },
      "source": [
        "def preprocess_sentence(w):\n",
        "\n",
        "    w.lower().strip()\n",
        "\n",
        "    # Чистим выборку от разных знаков препинания\n",
        "    # Убираем двойной пробел\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # еще чистим\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,^а-яА-Я]+\", \" \", w)\n",
        "\n",
        "    w = w.strip()\n",
        "\n",
        "    # добавляем токены начали окончания предложения\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:05:54.237054Z",
          "iopub.status.busy": "2021-04-02T02:05:54.236326Z",
          "iopub.status.idle": "2021-04-02T02:05:54.238623Z",
          "shell.execute_reply": "2021-04-02T02:05:54.239050Z"
        },
        "id": "opI2GzOt479E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7cb99be-1f81-4567-dec6-9ebd5cb6345d"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "rus_sentence = u\"Могу ли я одолжить эту книгу?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(rus_sentence))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> May I borrow this book ? <end>\n",
            "<start> Могу ли я одолжить эту книгу ? <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:05:54.244176Z",
          "iopub.status.busy": "2021-04-02T02:05:54.243533Z",
          "iopub.status.idle": "2021-04-02T02:05:54.245253Z",
          "shell.execute_reply": "2021-04-02T02:05:54.245661Z"
        },
        "id": "OHn4Dct23jEm"
      },
      "source": [
        "# 1. Считали\n",
        "# 2. почистили предложения\n",
        "# 3. Вернули в след формате: [ENGLISH, RUSSIAN, Какая-то фигня]\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "    word_pairs = [[preprocess_sentence(w) for w in line.split('\\t')]\n",
        "                for line in lines[:num_examples]]\n",
        "\n",
        "    return list(zip(*word_pairs))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:05:54.249732Z",
          "iopub.status.busy": "2021-04-02T02:05:54.249072Z",
          "iopub.status.idle": "2021-04-02T02:05:58.938561Z",
          "shell.execute_reply": "2021-04-02T02:05:58.937916Z"
        },
        "id": "cTbSbBz55QtF",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e07f14-21d0-4501-8873-91bba00571b7"
      },
      "source": [
        "%%time\n",
        "en,rus,non_know = create_dataset(path_to_file, None)\n",
        "print(en[10])\n",
        "print(rus[10])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> Run . <end>\n",
            "<start> Беги ! <end>\n",
            "CPU times: user 19.2 s, sys: 513 ms, total: 19.7 s\n",
            "Wall time: 19.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn0DjWn-AZHw",
        "outputId": "c84237c5-9673-4c78-ff53-39d288854cb8"
      },
      "source": [
        "print(en[10100])\n",
        "print(rus[10100])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> I felt strong . <end>\n",
            "<start> Я почувствовал себя сильным . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agLSBZpHAZHx",
        "outputId": "98a6e3e2-9b6b-4ec1-fd41-c2475dc615b4"
      },
      "source": [
        "print(en[-1])\n",
        "print(rus[-1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman . <end>\n",
            "<start> Несомненно , для каждого мужчины в этом мире где то есть подходящая женщина , которая может стать ему женой , обратное верно и для женщин . Но если учесть , что у человека может быть максимум несколько сотен знакомых , из которых лишь дюжина , а то и меньше , тех , кого он знает близко , а из этой дюжины у него один или от силы два друга , то можно легко увидеть , что с учетом миллионов живущих на Земле людей , ни один подходящий мужчина , возможно , еще не встретил подходящую женщину . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFixktSeAZHx",
        "outputId": "3380afa8-d28d-4380-9c02-20b0ffb09714"
      },
      "source": [
        "len(rus)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "421765"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:05:58.943609Z",
          "iopub.status.busy": "2021-04-02T02:05:58.942960Z",
          "iopub.status.idle": "2021-04-02T02:05:58.945350Z",
          "shell.execute_reply": "2021-04-02T02:05:58.944751Z"
        },
        "id": "bIOn8RCNDJXG"
      },
      "source": [
        "def tokenize(lang):\n",
        "    # токенизируем\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    # добавляем padding \n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "    return tensor, lang_tokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:05:58.950087Z",
          "iopub.status.busy": "2021-04-02T02:05:58.949434Z",
          "iopub.status.idle": "2021-04-02T02:05:58.951355Z",
          "shell.execute_reply": "2021-04-02T02:05:58.951753Z"
        },
        "id": "eAY9k49G3jE_"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "    # считали, вернули пары\n",
        "    targ_lang, inp_lang,non_known = create_dataset(path, num_examples)\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOi42V79Ydlr"
      },
      "source": [
        "### Limit the size of the dataset to experiment faster (optional)\n",
        "\n",
        "Обучение на всех данных длительный процесс. Можем взять кусок данных и надеяться что все заработает)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:05:58.956299Z",
          "iopub.status.busy": "2021-04-02T02:05:58.955657Z",
          "iopub.status.idle": "2021-04-02T02:06:00.872187Z",
          "shell.execute_reply": "2021-04-02T02:06:00.871006Z"
        },
        "id": "cnxC7q-j3jFD"
      },
      "source": [
        "# Выбор количества примеров это важная часть\n",
        "num_examples = 50000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file,\n",
        "                                                                num_examples)\n",
        "\n",
        "# считаем максимальные длины всех предложений\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:00.877965Z",
          "iopub.status.busy": "2021-04-02T02:06:00.877301Z",
          "iopub.status.idle": "2021-04-02T02:06:00.885478Z",
          "shell.execute_reply": "2021-04-02T02:06:00.885907Z"
        },
        "id": "4QILQkOs3jFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8756f15b-4e63-4dec-99e2-fbd84ea5ef35"
      },
      "source": [
        "# Трейн тест сплит\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40000 40000 10000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:00.890450Z",
          "iopub.status.busy": "2021-04-02T02:06:00.889841Z",
          "iopub.status.idle": "2021-04-02T02:06:00.891656Z",
          "shell.execute_reply": "2021-04-02T02:06:00.892047Z"
        },
        "id": "lJPmLZGMeD5q"
      },
      "source": [
        "# преврощение в словари\n",
        "def convert(lang, tensor):\n",
        "    for t in tensor:\n",
        "        if t != 0:\n",
        "            print(f'{t} ----> {lang.index_word[t]}')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoM9xVaTAZH0",
        "outputId": "77d0378b-369c-41b2-e9dc-b2e591c9a7b8"
      },
      "source": [
        "input_tensor_val"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,  228,   25, ...,    0,    0,    0],\n",
              "       [   1,  762,   18, ...,    0,    0,    0],\n",
              "       [   1,   12,  207, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1,    4, 1116, ...,    0,    0,    0],\n",
              "       [   1, 5433,   19, ...,    0,    0,    0],\n",
              "       [   1,    4, 9172, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:00.896593Z",
          "iopub.status.busy": "2021-04-02T02:06:00.895919Z",
          "iopub.status.idle": "2021-04-02T02:06:00.899899Z",
          "shell.execute_reply": "2021-04-02T02:06:00.900291Z"
        },
        "id": "VXukARTDd7MT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d69cce3-2269-4653-d5d7-a6bda31b7bd4"
      },
      "source": [
        "print(\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print()\n",
        "print(\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "9 ----> ты\n",
            "236 ----> хочешь\n",
            "474 ----> детей\n",
            "5 ----> ?\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "22 ----> do\n",
            "6 ----> you\n",
            "65 ----> want\n",
            "336 ----> kids\n",
            "7 ----> ?\n",
            "2 ----> <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:02.295930Z",
          "iopub.status.busy": "2021-04-02T02:06:02.295179Z",
          "iopub.status.idle": "2021-04-02T02:06:02.299622Z",
          "shell.execute_reply": "2021-04-02T02:06:02.300061Z"
        },
        "id": "TqHsArVZ3jFS"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 512\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:02.306484Z",
          "iopub.status.busy": "2021-04-02T02:06:02.303896Z",
          "iopub.status.idle": "2021-04-02T02:06:02.343281Z",
          "shell.execute_reply": "2021-04-02T02:06:02.343717Z"
        },
        "id": "qc6-NK1GtWQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e1f530-620b-4136-9bf8-903c0c348e4e"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([512, 15]), TensorShape([512, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## Write the encoder and decoder model\n",
        "\n",
        "Пример реалзиации энкодера и декодера для машинного перевода можно чекнуть тут [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt). Мы же посмотрим на attention [attention equations](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism). На картинке смотрим, что там происходит с вниманием. Объяснение взято из статьи [Luong's paper](https://arxiv.org/abs/1508.04025v5). \n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
        "\n",
        "Мы возвращаем все последовательность скрытых состояний из encoder *(batch_size, max_length, hidden_size)* и последнее скрытые состояния *(batch_size, hidden_size)*.\n",
        "\n",
        "Можем посмотреть на уравнения, которые у нас есть:\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
        "\n",
        "Мы возьме вот такой attention [Bahdanau attention](https://arxiv.org/pdf/1409.0473.pdf) для энкодера. и  можем взять описание того, что есть:\n",
        "\n",
        "* FC = Fully connected (dense) layer\n",
        "* EO = Encoder output\n",
        "* H = hidden state\n",
        "* X = input to the decoder\n",
        "\n",
        "И наш псевдо-код:\n",
        "\n",
        "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
        "* `attention weights = softmax(score, axis = 1)`. Softmax по умолчанию применяется к последней оси нашего тензора, но здесь мы хотим применить его к * 1-й оси *, так как наши данные имеют следующий вид * (batch_size, max_length, hidden_size) *. Max_length - длина нашей последовательности. И мы хотим дать вес каждому элементу последовательности, поэтому и применяем softmax именно так.\n",
        "\n",
        "* `context vector = sum(attention weights * EO, axis = 1)`. \n",
        "* `embedding output` = Эмбедим наш выход.\n",
        "* `merged vector = concat(embedding output, context vector)`\n",
        "* И этот вектор мы и отдаем дальше\n",
        "\n",
        "Смотрим на реализацию!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:02.350331Z",
          "iopub.status.busy": "2021-04-02T02:06:02.349711Z",
          "iopub.status.idle": "2021-04-02T02:06:02.351948Z",
          "shell.execute_reply": "2021-04-02T02:06:02.351453Z"
        },
        "id": "nZ2rI24i3jFg"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:02.356314Z",
          "iopub.status.busy": "2021-04-02T02:06:02.355683Z",
          "iopub.status.idle": "2021-04-02T02:06:04.086751Z",
          "shell.execute_reply": "2021-04-02T02:06:04.086199Z"
        },
        "id": "60gSVh05Jl6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ae33c5-e638-4d4d-dc0e-b116ab9b2efb"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# пример всего того, что у нас получилося\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
        "print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (512, 15, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (512, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:04.093942Z",
          "iopub.status.busy": "2021-04-02T02:06:04.093325Z",
          "iopub.status.idle": "2021-04-02T02:06:04.094939Z",
          "shell.execute_reply": "2021-04-02T02:06:04.095292Z"
        },
        "id": "umohpBN2OM94"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        # query hidden state shape == (batch_size, hidden size)\n",
        "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # values shape == (batch_size, max_len, hidden size)\n",
        "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:04.104567Z",
          "iopub.status.busy": "2021-04-02T02:06:04.103963Z",
          "iopub.status.idle": "2021-04-02T02:06:04.468862Z",
          "shell.execute_reply": "2021-04-02T02:06:04.468297Z"
        },
        "id": "k534zTHiDjQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95f59e5-da79-4d70-a534-cf32493128ba"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units)\", attention_result.shape)\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1)\", attention_weights.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch size, units) (512, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (512, 15, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:04.477387Z",
          "iopub.status.busy": "2021-04-02T02:06:04.476693Z",
          "iopub.status.idle": "2021-04-02T02:06:04.479107Z",
          "shell.execute_reply": "2021-04-02T02:06:04.478602Z"
        },
        "id": "yJ_B3mhW3jFk"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        output, state = self.gru(x)\n",
        "\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:04.496328Z",
          "iopub.status.busy": "2021-04-02T02:06:04.485540Z",
          "iopub.status.idle": "2021-04-02T02:06:04.522733Z",
          "shell.execute_reply": "2021-04-02T02:06:04.522041Z"
        },
        "id": "P5UY8wko3jFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df108627-0e48-4535-b80f-ea96fbc3db03"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (512, 4774)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "## Define the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:04.530148Z",
          "iopub.status.busy": "2021-04-02T02:06:04.528999Z",
          "iopub.status.idle": "2021-04-02T02:06:04.531358Z",
          "shell.execute_reply": "2021-04-02T02:06:04.531807Z"
        },
        "id": "WmTHr5iV3jFr"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMVWzzsfNl4e"
      },
      "source": [
        "## Checkpoints (Object-based saving)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:04.537629Z",
          "iopub.status.busy": "2021-04-02T02:06:04.536506Z",
          "iopub.status.idle": "2021-04-02T02:06:04.539341Z",
          "shell.execute_reply": "2021-04-02T02:06:04.538675Z"
        },
        "id": "Zj8bXQTgNwrF"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpObfY22IddU"
      },
      "source": [
        "## Training\n",
        "\n",
        "\n",
        "1. Энкодим наш вход\n",
        "2. Выход энкодера засовываем в декодер\n",
        "3. Прогноз декодера используем для расчета лосса и возвращаем скрытое состояния для следующего прогноза\n",
        "4. Используем *teacher forcing* решаем какой инпут дать декодеру дальше.\n",
        "5. *Teacher forcing* это техника когда *target word* используем как *next input* декодер.\n",
        "6. Итоговый результат используем как результат и считаем лосс"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:04.548046Z",
          "iopub.status.busy": "2021-04-02T02:06:04.546948Z",
          "iopub.status.idle": "2021-04-02T02:06:04.549768Z",
          "shell.execute_reply": "2021-04-02T02:06:04.549234Z"
        },
        "id": "sC9ArXSsVfqn"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        # Teacher forcing - скармливаем\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # passing enc_output to the decoder\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "            # using teacher forcing\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:06:04.557511Z",
          "iopub.status.busy": "2021-04-02T02:06:04.556354Z",
          "iopub.status.idle": "2021-04-02T02:08:53.650446Z",
          "shell.execute_reply": "2021-04-02T02:08:53.649859Z"
        },
        "id": "ddefjBMa3jF0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af02a37e-af21-434a-f1b6-015db31f5ba2"
      },
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
        "        # сохранялка\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 5.3110\n",
            "Epoch 1 Loss 2.8268\n",
            "Time taken for 1 epoch 60.07 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.2561\n",
            "Epoch 2 Loss 2.0119\n",
            "Time taken for 1 epoch 46.27 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.7420\n",
            "Epoch 3 Loss 1.6699\n",
            "Time taken for 1 epoch 45.43 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.4953\n",
            "Epoch 4 Loss 1.4591\n",
            "Time taken for 1 epoch 46.02 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.3339\n",
            "Epoch 5 Loss 1.2955\n",
            "Time taken for 1 epoch 45.52 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.1947\n",
            "Epoch 6 Loss 1.1465\n",
            "Time taken for 1 epoch 46.11 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.0205\n",
            "Epoch 7 Loss 1.0082\n",
            "Time taken for 1 epoch 45.51 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.8723\n",
            "Epoch 8 Loss 0.8828\n",
            "Time taken for 1 epoch 46.15 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.7857\n",
            "Epoch 9 Loss 0.7666\n",
            "Time taken for 1 epoch 45.55 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.6642\n",
            "Epoch 10 Loss 0.6572\n",
            "Time taken for 1 epoch 46.21 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.5498\n",
            "Epoch 11 Loss 0.5573\n",
            "Time taken for 1 epoch 45.44 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.4792\n",
            "Epoch 12 Loss 0.4673\n",
            "Time taken for 1 epoch 46.09 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.3502\n",
            "Epoch 13 Loss 0.3909\n",
            "Time taken for 1 epoch 45.53 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.3052\n",
            "Epoch 14 Loss 0.3269\n",
            "Time taken for 1 epoch 46.11 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.2639\n",
            "Epoch 15 Loss 0.2731\n",
            "Time taken for 1 epoch 45.51 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.2430\n",
            "Epoch 16 Loss 0.2277\n",
            "Time taken for 1 epoch 46.08 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.1641\n",
            "Epoch 17 Loss 0.1944\n",
            "Time taken for 1 epoch 45.52 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.1622\n",
            "Epoch 18 Loss 0.1653\n",
            "Time taken for 1 epoch 46.10 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.1319\n",
            "Epoch 19 Loss 0.1422\n",
            "Time taken for 1 epoch 45.43 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.1113\n",
            "Epoch 20 Loss 0.1228\n",
            "Time taken for 1 epoch 46.09 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.1065\n",
            "Epoch 21 Loss 0.1098\n",
            "Time taken for 1 epoch 45.44 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.0867\n",
            "Epoch 22 Loss 0.0980\n",
            "Time taken for 1 epoch 46.10 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.0761\n",
            "Epoch 23 Loss 0.0889\n",
            "Time taken for 1 epoch 45.46 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.0702\n",
            "Epoch 24 Loss 0.0807\n",
            "Time taken for 1 epoch 46.17 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.0637\n",
            "Epoch 25 Loss 0.0739\n",
            "Time taken for 1 epoch 45.39 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss 0.0600\n",
            "Epoch 26 Loss 0.0679\n",
            "Time taken for 1 epoch 46.06 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss 0.0549\n",
            "Epoch 27 Loss 0.0623\n",
            "Time taken for 1 epoch 45.43 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss 0.0448\n",
            "Epoch 28 Loss 0.0593\n",
            "Time taken for 1 epoch 46.10 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss 0.0465\n",
            "Epoch 29 Loss 0.0575\n",
            "Time taken for 1 epoch 45.51 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 0.0454\n",
            "Epoch 30 Loss 0.0548\n",
            "Time taken for 1 epoch 46.08 sec\n",
            "\n",
            "Epoch 31 Batch 0 Loss 0.0446\n",
            "Epoch 31 Loss 0.0520\n",
            "Time taken for 1 epoch 81.91 sec\n",
            "\n",
            "Epoch 32 Batch 0 Loss 0.0419\n",
            "Epoch 32 Loss 0.0501\n",
            "Time taken for 1 epoch 46.47 sec\n",
            "\n",
            "Epoch 33 Batch 0 Loss 0.0409\n",
            "Epoch 33 Loss 0.0487\n",
            "Time taken for 1 epoch 45.65 sec\n",
            "\n",
            "Epoch 34 Batch 0 Loss 0.0379\n",
            "Epoch 34 Loss 0.0471\n",
            "Time taken for 1 epoch 46.22 sec\n",
            "\n",
            "Epoch 35 Batch 0 Loss 0.0428\n",
            "Epoch 35 Loss 0.0460\n",
            "Time taken for 1 epoch 45.50 sec\n",
            "\n",
            "Epoch 36 Batch 0 Loss 0.0399\n",
            "Epoch 36 Loss 0.0449\n",
            "Time taken for 1 epoch 46.19 sec\n",
            "\n",
            "Epoch 37 Batch 0 Loss 0.0342\n",
            "Epoch 37 Loss 0.0449\n",
            "Time taken for 1 epoch 45.61 sec\n",
            "\n",
            "Epoch 38 Batch 0 Loss 0.0371\n",
            "Epoch 38 Loss 0.0442\n",
            "Time taken for 1 epoch 46.15 sec\n",
            "\n",
            "Epoch 39 Batch 0 Loss 0.0344\n",
            "Epoch 39 Loss 0.0438\n",
            "Time taken for 1 epoch 45.55 sec\n",
            "\n",
            "Epoch 40 Batch 0 Loss 0.0330\n",
            "Epoch 40 Loss 0.0434\n",
            "Time taken for 1 epoch 46.24 sec\n",
            "\n",
            "Epoch 41 Batch 0 Loss 0.0347\n",
            "Epoch 41 Loss 0.0451\n",
            "Time taken for 1 epoch 45.48 sec\n",
            "\n",
            "Epoch 42 Batch 0 Loss 0.0333\n",
            "Epoch 42 Loss 0.0450\n",
            "Time taken for 1 epoch 46.22 sec\n",
            "\n",
            "Epoch 43 Batch 0 Loss 0.0447\n",
            "Epoch 43 Loss 0.0433\n",
            "Time taken for 1 epoch 45.50 sec\n",
            "\n",
            "Epoch 44 Batch 0 Loss 0.0375\n",
            "Epoch 44 Loss 0.0428\n",
            "Time taken for 1 epoch 46.26 sec\n",
            "\n",
            "Epoch 45 Batch 0 Loss 0.0338\n",
            "Epoch 45 Loss 0.0424\n",
            "Time taken for 1 epoch 45.41 sec\n",
            "\n",
            "Epoch 46 Batch 0 Loss 0.0322\n",
            "Epoch 46 Loss 0.0409\n",
            "Time taken for 1 epoch 46.00 sec\n",
            "\n",
            "Epoch 47 Batch 0 Loss 0.0323\n",
            "Epoch 47 Loss 0.0406\n",
            "Time taken for 1 epoch 45.11 sec\n",
            "\n",
            "Epoch 48 Batch 0 Loss 0.0337\n",
            "Epoch 48 Loss 0.0402\n",
            "Time taken for 1 epoch 45.82 sec\n",
            "\n",
            "Epoch 49 Batch 0 Loss 0.0298\n",
            "Epoch 49 Loss 0.0405\n",
            "Time taken for 1 epoch 45.53 sec\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.0315\n",
            "Epoch 50 Loss 0.0407\n",
            "Time taken for 1 epoch 46.18 sec\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.0349\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-64e624768d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "## Translate\n",
        "\n",
        "* Все похоже на обучение, только мы не можем подсовывать нормальное слово в декодер.\n",
        "* Как только модель предсказала конец предложения останавливаем обучения\n",
        "* Храним выводы attention на каждом шаге\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:08:53.660425Z",
          "iopub.status.busy": "2021-04-02T02:08:53.659728Z",
          "iopub.status.idle": "2021-04-02T02:08:53.662480Z",
          "shell.execute_reply": "2021-04-02T02:08:53.662920Z"
        },
        "id": "EbQpyYs13jF_"
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:08:53.669558Z",
          "iopub.status.busy": "2021-04-02T02:08:53.668870Z",
          "iopub.status.idle": "2021-04-02T02:08:53.670786Z",
          "shell.execute_reply": "2021-04-02T02:08:53.671189Z"
        },
        "id": "s5hQWlbN3jGF"
      },
      "source": [
        "# рисовалка внимания\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:08:53.676258Z",
          "iopub.status.busy": "2021-04-02T02:08:53.675621Z",
          "iopub.status.idle": "2021-04-02T02:08:53.677985Z",
          "shell.execute_reply": "2021-04-02T02:08:53.677475Z"
        },
        "id": "sl9zUHzg3jGI"
      },
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input:', sentence)\n",
        "    print('Predicted translation:', result)\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')),\n",
        "                                  :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n250XbnjOaqP"
      },
      "source": [
        "## Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:08:53.681733Z",
          "iopub.status.busy": "2021-04-02T02:08:53.681071Z",
          "iopub.status.idle": "2021-04-02T02:08:53.885040Z",
          "shell.execute_reply": "2021-04-02T02:08:53.884482Z"
        },
        "id": "UJpT9D5_OgP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e741f44-d7da-4c00-953c-e4dd8db4d999"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f96aa61b450>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-02T02:08:53.889827Z",
          "iopub.status.busy": "2021-04-02T02:08:53.889126Z",
          "iopub.status.idle": "2021-04-02T02:08:54.176938Z",
          "shell.execute_reply": "2021-04-02T02:08:54.176294Z"
        },
        "id": "WrAM0FDomq3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "8b9cc88b-850a-4d74-e00a-3fd5ae65b25d"
      },
      "source": [
        "translate(u'я очень старый человек .')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> я очень старый человек . <end>\n",
            "Predicted translation: i a very very old thin shy . shy \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "lCsf4iGITFxf",
        "outputId": "4e87bb91-2829-4a34-b0f4-2047427967ac"
      },
      "source": [
        "translate(u'мы поможем тебе.')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> мы поможем тебе . <end>\n",
            "Predicted translation: we you you you you you help help help \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "sOKZClZVP9RF",
        "outputId": "9ac78fc9-9825-4c0d-e291-671e2585e7bf"
      },
      "source": [
        "translate(u'мы помочь тебе.')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> мы помочь тебе . <end>\n",
            "Predicted translation: we help help help help you you you you \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTe5P5ioMJwN"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "* Эксперементы :)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlkYPCfuAZIE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}